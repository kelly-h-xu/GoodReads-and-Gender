{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d82a587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import glob, csv\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "romance_df = pd.read_csv('english_romance_reviews_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c0766b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3217531, 12)\n",
      "0    [spoiler, alert, day, elizabeth, book, store, ...\n",
      "1    [hard, believe, true, i'll, take, author's, wo...\n",
      "2    [ehhhhhh, really, nothing, rave, poorly, writt...\n",
      "3    [enjoyable, read, liked, connie, typical, cold...\n",
      "4    [definitely, many, book, lately, theme, woman,...\n",
      "Name: cleaned_review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(romance_df.shape)\n",
    "romance_df[\"cleaned_review\"] = romance_df[\"cleaned_review\"].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b1624ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['spoiler', 'alert', 'day', 'elizabeth', 'book', 'store', 'she', 'saw', 'book', 'said', 'she', 'really', 'wanted', 'read', 'horror', 'thought', 'reading', 'thought', \"'chick\", \"book'\", 'immediately', 'countered', 'she', 'would', 'read', 'one', 'favorites:', 'dune', 'she', 'agreed', 'read', 'admit', 'good', 'damn', 'good', 'even', 'though', 'serious', 'lack', 'gratuitous', 'violence', 'tore', 'several', 'day', 'austen', 'amazing', 'writer', 'particular', 'talent', 'explaining', 'her', 'character', 'deep', 'motivation', 'prejudice', 'defining', 'sentence', 'think', 'favorite', 'part', 'unwinding', \"elizabeths'\", 'prejudice', 'darcy', 'done', 'slowly', 'artfully', 'believably', 'reader', 'completely', 'pulled', 'story', 'definite', 'period', 'piece', 'funny', 'observations:', 'nobody', 'book', 'job', '-', 'earned', 'income', 'estate', '-', 'since', 'nobody', 'job', 'spent', 'day', 'gossiping', '-', 'people', 'judged', 'living', 'family', 'behaved', 'society', 'completely', 'different', 'today', '-', 'dating', 'much', 'tougher', 'back', 'needed', 'least', 'date', 'get', 'anywhere', 'probably', 'marry', 'order', 'way', 'joke', 'aside', 'classic', 'highly', 'recommend', 'guy', 'girl'], ['hard', 'believe', 'true', \"i'll\", 'take', \"author's\", 'word', \"i've\", 'always', 'open', 'mind', 'toward', 'woman', 'choose', 'work', 'trade', 'lot', 'compassion', 'feel', 'often', 'desperation', 'making', 'choice', 'sell', 'body', 'shown', 'story', 'feel', 'like', 'story', 'time', 'aimed', '\"sexy\"', 'rather', '\"sexual\"', 'make', 'sense', 'feel', 'took', 'away', 'biographical', 'focus', 'edged', 'erotica', 'however', \"didn't\", 'effect', 'overall', 'opinion', 'greatly', \"couldn't\", 'put', 'licentious', 'reason', 'simply', 'wanted', 'know', 'happened', 'next', \"woman's\", 'life'], ['ehhhhhh', 'really', 'nothing', 'rave', 'poorly', 'written', 'term', 'style', 'technical', 'aspect', 'story', 'particularly', 'interesting', 'feel', 'bit', 'overdone', 'stand', 'vampire', 'fiction', '\"romance\"', 'happened', 'far', 'quickly', 'opinion', 'would', 'expect', 'vampire', 'lived', 'long', 'little', 'harder', 'get', 'sack', 'even', 'short', 'story', 'short', 'feel', 'like', 'author', 'capable', 'would', 'like', 'see', 'longer', 'story', 'her'], ['enjoyable', 'read', 'liked', 'connie', 'typical', 'cold-hearted', 'sexy', 'perfect', 'genius', 'vampire', 'hunter', \"she's\", 'like', 'real', 'person', 'flaw', 'weakness', 'fear', 'really', 'enjoyed', 'style', 'writing', \"i'm\", 'usually', 'big', 'fan', 'first', 'person', 'perspective', 'feel', 'author', 'used', 'great', 'balance', 'dialogue', 'descriptive', 'text', \"character's\", '\"voice\"', 'really', 'shone', 'without', 'colloquial', 'vampire', 'fiction', 'tricky', 'subject', 'day', \"it's\", 'becoming', 'common', 'feel', 'like', 'book', 'unique', 'enough', 'stand', \"can't\", 'wait', 'read'], ['definitely', 'many', 'book', 'lately', 'theme', 'woman', 'going', 'isolated', 'cabin', 'escape', 'break', \"don't\", 'think', 'book', 'discredited', 'enjoyable', 'mystery', 'predictable', 'style', 'writing', 'captured', 'essence', 'story']]\n"
     ]
    }
   ],
   "source": [
    "word2vec_romance_reviews = romance_df[\"cleaned_review\"].tolist()\n",
    "print(word2vec_romance_reviews[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34411dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_romance = Word2Vec(word2vec_romance_reviews, min_count=3, window=6, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b2f6336",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word2vec_romance.wv)\n",
    "word2vec_romance.save(r'romance_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "446d6dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import glob, csv\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "mystery_df = pd.read_csv('english_mystery_reviews_clean.csv')\n",
    "mystery_df[\"cleaned_review\"] = mystery_df[\"cleaned_review\"].apply(eval)\n",
    "word2vec_mystery_reviews = mystery_df[\"cleaned_review\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "682e417f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243803\n"
     ]
    }
   ],
   "source": [
    "word2vec_mystery = Word2Vec(word2vec_mystery_reviews, min_count=3, window=6, epochs=5)\n",
    "print(len(word2vec_mystery.wv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73604ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "comics_df = pd.read_csv(\"english_comics_reviews_clean.csv\") \n",
    "comics_df[\"cleaned_review\"] = comics_df[\"cleaned_review\"].apply(eval)\n",
    "word2vec_comics_reviews = comics_df[\"cleaned_review\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1cb1af92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107665\n"
     ]
    }
   ],
   "source": [
    "word2vec_comics = Word2Vec(word2vec_comics_reviews, min_count=3, window=6, epochs=6)\n",
    "print(len(word2vec_comics.wv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7d9ce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_mystery.save(r'mystery_model')\n",
    "word2vec_comics.save(r'comics_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7b991f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "poetry_df = pd.read_csv('english_poetry_reviews_clean.csv')\n",
    "poetry_df[\"cleaned_review\"] = poetry_df[\"cleaned_review\"].apply(eval)\n",
    "word2vec_poetry_reviews = poetry_df[\"cleaned_review\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "59734727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65633\n"
     ]
    }
   ],
   "source": [
    "word2vec_poetry = Word2Vec(word2vec_poetry_reviews, min_count=3, window=6, epochs=8)\n",
    "print(len(word2vec_poetry.wv))\n",
    "word2vec_poetry.save(r\"poetry_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "041c7bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "children_df = pd.read_csv('english_children_reviews_clean.csv')\n",
    "children_df[\"cleaned_review\"] = children_df[\"cleaned_review\"].apply(eval)\n",
    "word2vec_children_reviews = children_df[\"cleaned_review\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a63951bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108687\n"
     ]
    }
   ],
   "source": [
    "word2vec_children = Word2Vec(word2vec_children_reviews, min_count=3, window=6, epochs=6)\n",
    "print(len(word2vec_children.wv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e72d921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_children.save(r'children_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
